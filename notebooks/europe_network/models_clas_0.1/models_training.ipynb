{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import itertools\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "from models.train import train, test\n",
    "from models.models import GCN, GAT, GraphSAGE, FNN\n",
    "from models.utils import ContagionDataset, set_seed\n",
    "from sklearn.metrics import matthews_corrcoef, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty(ld, indent=0):\n",
    "    return None\n",
    "    with open('result.txt', 'w', encoding='utf-8') as file:\n",
    "        for d in tqdm(ld):\n",
    "            file.write('{' + '\\n')\n",
    "            for key, value in d.items():\n",
    "                file.write('\\t' * (indent+1) + str(key) + ':' + str(value) + '\\n')\n",
    "                # file.write('\\t' * (indent+1) + str(key) + '\\n')\n",
    "                # file.write('\\t' * (indent+2) + str(value) + '\\n')\n",
    "            file.write('},\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_train = False\n",
    "\n",
    "seed = 4444\n",
    "set_seed(seed)\n",
    "\n",
    "metric_filter_1 = 'val_mcc'\n",
    "metric_filter_2 = 'test_mcc'\n",
    "\n",
    "data_dir = '../data'\n",
    "log_path = './logs'\n",
    "save_path = './saved'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big dataset: Additional stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets_lengths = (0.07, 0.03, 0.9)\n",
    "target = 'additional_stress'\n",
    "\n",
    "dataset = ContagionDataset(\n",
    "    raw_dir=data_dir,\n",
    "    drop_edges=0,\n",
    "    sets_lengths=sets_lengths,\n",
    "    target = target,\n",
    ")\n",
    "\n",
    "out_feats = dataset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(101)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dataset[0].ndata['train_mask']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(43)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dataset[0].ndata['val_mask']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1300)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dataset[0].ndata['test_mask']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_small_acc_train = {}\n",
    "dict_small_acc_val = {}\n",
    "dict_small_acc_test = {}\n",
    "dict_small_rmse_train = {}\n",
    "dict_small_rmse_val = {}\n",
    "dict_small_rmse_test = {}\n",
    "dict_small_mcc_train = {}\n",
    "dict_small_mcc_val = {}\n",
    "dict_small_mcc_test = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train,x_test,y_train,y_test = train_test_split(dataset.node_features[0].to_numpy(), dataset.targets[0], test_size=0.25, random_state=seed)\n",
    "g_data = dataset.graphs[0].ndata\n",
    "feats = g_data['feat']\n",
    "labels = g_data['label']\n",
    "train_mask = g_data['train_mask']\n",
    "val_mask = g_data['val_mask']\n",
    "test_mask = g_data['test_mask']\n",
    "\n",
    "# train + val for training, test for test\n",
    "x_train,x_test = feats[torch.logical_not(test_mask)], feats[test_mask]\n",
    "y_train,y_test = labels[torch.logical_not(test_mask)], labels[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([144, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1300, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.75      0.53       325\n",
      "           1       0.45      0.03      0.06       315\n",
      "           2       0.38      0.69      0.49       327\n",
      "           3       0.93      0.24      0.38       333\n",
      "\n",
      "    accuracy                           0.43      1300\n",
      "   macro avg       0.54      0.43      0.36      1300\n",
      "weighted avg       0.55      0.43      0.37      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression(multi_class='multinomial',random_state=seed, max_iter=800).fit(x_train, y_train)\n",
    "print(classification_report(y_true=y_test, y_pred=model_lr.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.3958333333333333\n",
      "Test accuracy: 0.42923076923076925\n",
      "Train rmse: 1.2162099599438687\n",
      "Test rmse: 1.2275679520593055\n",
      "Train mcc: 0.24040692589472054\n",
      "Test mcc: 0.271607138268044\n"
     ]
    }
   ],
   "source": [
    "dict_small_acc_train['logistic_regression'] = model_lr.score(x_train, y_train)\n",
    "dict_small_acc_test['logistic_regression'] = model_lr.score(x_test, y_test)\n",
    "print(f\"Train accuracy: {dict_small_acc_train['logistic_regression']}\")\n",
    "print(f\"Test accuracy: {dict_small_acc_test['logistic_regression']}\")\n",
    "\n",
    "dict_small_rmse_train['logistic_regression'] = mean_squared_error(y_true=y_train,y_pred=model_lr.predict(x_train), squared=False)\n",
    "dict_small_rmse_test['logistic_regression'] = mean_squared_error(y_true=y_test,y_pred=model_lr.predict(x_test), squared=False)\n",
    "print(f\"Train rmse: {dict_small_rmse_train['logistic_regression']}\")\n",
    "print(f\"Test rmse: {dict_small_rmse_test['logistic_regression']}\")\n",
    "\n",
    "dict_small_mcc_train['logistic_regression'] = matthews_corrcoef(y_true=y_train,y_pred=model_lr.predict(x_train))\n",
    "dict_small_mcc_test['logistic_regression'] = matthews_corrcoef(y_true=y_test,y_pred=model_lr.predict(x_test))\n",
    "print(f\"Train mcc: {dict_small_mcc_train['logistic_regression']}\")\n",
    "print(f\"Test mcc: {dict_small_mcc_test['logistic_regression']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # x_train_rf,x_val_rf,y_train_rf,y_val_rf = train_test_split(x_train, y_train, test_size=0.2, random_state=seed)\n",
    "# x_train_rf,x_val_rf,x_test_rf = feats[train_mask], feats[val_mask], feats[test_mask]\n",
    "# y_train_rf,y_val_rf,y_test_rf = labels[train_mask], labels[val_mask], labels[test_mask]\n",
    "x_train_rf = x_train\n",
    "y_train_rf = y_train\n",
    "x_val_rf = x_test\n",
    "y_val_rf = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:01<00:00, 11.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.45      0.49       325\n",
      "           1       0.42      0.55      0.48       315\n",
      "           2       0.70      0.51      0.59       327\n",
      "           3       0.76      0.85      0.80       333\n",
      "\n",
      "    accuracy                           0.59      1300\n",
      "   macro avg       0.60      0.59      0.59      1300\n",
      "weighted avg       0.61      0.59      0.59      1300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n = 20\n",
    "num_nodes = x_train_rf.shape[0]\n",
    "model_rf = None\n",
    "val_acc = 0.0\n",
    "for k in trange(1,num_nodes, (num_nodes - 1) // n):\n",
    "    tmp = RandomForestClassifier(random_state=seed, n_estimators=k).fit(x_train_rf,y_train_rf)\n",
    "    tmp_acc = tmp.score(x_val_rf, y_val_rf)\n",
    "    if val_acc < tmp_acc:\n",
    "        val_acc = tmp_acc\n",
    "        model_rf = tmp\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred=model_rf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=64, random_state=4444)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.0\n",
      "Val accuracy: 0.5930769230769231\n",
      "Test accuracy: 0.5930769230769231\n",
      "Train rmse: 0.0\n",
      "Val rmse: 0.978617549246031\n",
      "Test rmse: 0.978617549246031\n",
      "Train mcc: 1.0\n",
      "Val mcc: 0.46179019637476154\n",
      "Test mcc: 0.46179019637476154\n"
     ]
    }
   ],
   "source": [
    "dict_small_acc_train['random_forest'] = model_rf.score(x_train_rf, y_train_rf)\n",
    "dict_small_acc_val['random_forest'] = model_rf.score(x_val_rf, y_val_rf)\n",
    "dict_small_acc_test['random_forest'] = model_rf.score(x_test, y_test)\n",
    "print(f\"Train accuracy: {dict_small_acc_train['random_forest']}\")\n",
    "print(f\"Val accuracy: {dict_small_acc_val['random_forest']}\")\n",
    "print(f\"Test accuracy: {dict_small_acc_test['random_forest']}\")\n",
    "\n",
    "dict_small_rmse_train['random_forest'] = mean_squared_error(y_true=y_train_rf,y_pred=model_rf.predict(x_train_rf), squared=False)\n",
    "dict_small_rmse_val['random_forest'] = mean_squared_error(y_true=y_val_rf,y_pred=model_rf.predict(x_val_rf), squared=False)\n",
    "dict_small_rmse_test['random_forest'] = mean_squared_error(y_true=y_test,y_pred=model_rf.predict(x_test), squared=False)\n",
    "print(f\"Train rmse: {dict_small_rmse_train['random_forest']}\")\n",
    "print(f\"Val rmse: {dict_small_rmse_val['random_forest']}\")\n",
    "print(f\"Test rmse: {dict_small_rmse_test['random_forest']}\")\n",
    "\n",
    "dict_small_mcc_train['random_forest'] = matthews_corrcoef(y_true=y_train_rf,y_pred=model_rf.predict(x_train_rf))\n",
    "dict_small_mcc_val['random_forest'] = matthews_corrcoef(y_true=y_val_rf,y_pred=model_rf.predict(x_val_rf))\n",
    "dict_small_mcc_test['random_forest'] = matthews_corrcoef(y_true=y_test,y_pred=model_rf.predict(x_test))\n",
    "print(f\"Train mcc: {dict_small_mcc_train['random_forest']}\")\n",
    "print(f\"Val mcc: {dict_small_mcc_val['random_forest']}\")\n",
    "print(f\"Test mcc: {dict_small_mcc_test['random_forest']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.61      0.47       325\n",
      "           1       0.35      0.39      0.37       315\n",
      "           2       0.50      0.20      0.28       327\n",
      "           3       0.64      0.60      0.62       333\n",
      "\n",
      "    accuracy                           0.45      1300\n",
      "   macro avg       0.47      0.45      0.44      1300\n",
      "weighted avg       0.47      0.45      0.44      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_knn = KNeighborsClassifier(n_neighbors=out_feats).fit(x_train,y_train)\n",
    "print(classification_report(y_true=y_test, y_pred=model_knn.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.6736111111111112\n",
      "Test accuracy: 0.45\n",
      "Train rmse: 1.0\n",
      "Test rmse: 1.3032503744336843\n",
      "Train mcc: 0.574872465961017\n",
      "Test mcc: 0.2755059559376615\n"
     ]
    }
   ],
   "source": [
    "dict_small_acc_train['knn_classifier'] = model_knn.score(x_train_rf, y_train_rf)\n",
    "dict_small_acc_test['knn_classifier'] = model_knn.score(x_test, y_test)\n",
    "print(f\"Train accuracy: {dict_small_acc_train['knn_classifier']}\")\n",
    "print(f\"Test accuracy: {dict_small_acc_test['knn_classifier']}\")\n",
    "\n",
    "dict_small_rmse_train['knn_classifier'] = mean_squared_error(y_true=y_train_rf,y_pred=model_knn.predict(x_train_rf), squared=False)\n",
    "dict_small_rmse_test['knn_classifier'] = mean_squared_error(y_true=y_test,y_pred=model_knn.predict(x_test), squared=False)\n",
    "print(f\"Train rmse: {dict_small_rmse_train['knn_classifier']}\")\n",
    "print(f\"Test rmse: {dict_small_rmse_test['knn_classifier']}\")\n",
    "\n",
    "dict_small_mcc_train['knn_classifier'] = matthews_corrcoef(y_true=y_train_rf,y_pred=model_knn.predict(x_train_rf))\n",
    "dict_small_mcc_test['knn_classifier'] = matthews_corrcoef(y_true=y_test,y_pred=model_knn.predict(x_test))\n",
    "print(f\"Train mcc: {dict_small_mcc_train['knn_classifier']}\")\n",
    "print(f\"Test mcc: {dict_small_mcc_test['knn_classifier']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = f'{save_path}_fnn'\n",
    "log_dir = f'{log_path}_fnn'\n",
    "\n",
    "dataset_val = ContagionDataset(\n",
    "    raw_dir=data_dir,\n",
    "    drop_edges=0,\n",
    "    sets_lengths=sets_lengths,\n",
    "    add_self_loop = False,\n",
    "    target = target,\n",
    ")\n",
    "\n",
    "fnn_model = dict(\n",
    "    in_features=[len(dataset_val.node_attributes)],\n",
    "    h_features=[[100], [100] * 2, [100] * 3, [200], [200]*2,[200]*3],\n",
    "    out_features=[dataset_val.num_classes],\n",
    "    activation=[torch.nn.ReLU()],\n",
    "    norm_nodes = [None, 'bn', 'gn'],\n",
    "    dropout=[0.2, 0.0],\n",
    "    # other\n",
    "    lr=[1e-1],\n",
    "    label_smoothing=[0.0, 0.2],\n",
    ")\n",
    "list_model = [dict(zip(fnn_model.keys(), k)) for k in itertools.product(*fnn_model.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if do_train:\n",
    "    for d in tqdm(list_model):\n",
    "        d = d.copy()\n",
    "        lr = d.pop('lr')\n",
    "        ls = d.pop('label_smoothing')\n",
    "\n",
    "        train(\n",
    "            model=FNN(**d),\n",
    "            dict_model=d,\n",
    "            dataset_train=dataset_val,\n",
    "            dataset_val=dataset_val,\n",
    "            log_dir=log_dir,\n",
    "            save_path=save_model,\n",
    "            lr=lr,\n",
    "            optimizer_name=\"adamw\",\n",
    "            n_epochs=100,\n",
    "            scheduler_mode='max_val_mcc',\n",
    "            debug_mode=False,\n",
    "            steps_save=10,\n",
    "            use_cpu=False,\n",
    "            label_smoothing=ls,\n",
    "            use_edge_weight=False,\n",
    "            scheduler_patience=20,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1299/1299 [00:49<00:00, 26.22it/s]\n"
     ]
    }
   ],
   "source": [
    "res_edges_fnn = test(\n",
    "    dataset=dataset_val,\n",
    "    save_path=save_model,\n",
    "    n_runs=1,\n",
    "    debug_mode=False,\n",
    "    use_cpu=False,\n",
    "    save=True,\n",
    "    use_edge_weight=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_features': 4,\n",
       " 'h_features': [200, 200, 200],\n",
       " 'out_features': 4,\n",
       " 'activation': ReLU(),\n",
       " 'norm_nodes': 'gn',\n",
       " 'dropout': 0.0,\n",
       " 'train_lr': 0.1,\n",
       " 'train_optimizer_name': 'adamw',\n",
       " 'train_scheduler_mode': 'max_val_mcc',\n",
       " 'train_label_smoothing': 0.0,\n",
       " 'train_use_edge_weight': False,\n",
       " 'train_scheduler_patience': 20,\n",
       " 'train_self_loop': False,\n",
       " 'train_drop_edges': 0,\n",
       " 'train_loss': 0.63593006,\n",
       " 'train_acc': 0.7623761892318726,\n",
       " 'val_acc': 0.6511626243591309,\n",
       " 'epoch': 80,\n",
       " 'model_class': 'fnn',\n",
       " 'path_name': '0.65_4_[200_200_200]_4_ReLU()_gn_0.0_0.1_adamw_max_val_mcc_0.0_False_20_False_0_80',\n",
       " 'train_mcc': 0.6864419429227578,\n",
       " 'val_mcc': 0.5332591106146854,\n",
       " 'test_mcc': 0.44188670454440704,\n",
       " 'train_rmse': 0.6821631290633241,\n",
       " 'val_rmse': 0.914991421995628,\n",
       " 'test_rmse': 0.9833224684319366,\n",
       " 'test_acc': 0.5746153593063354}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_edges = res_edges_fnn\n",
    "res_edges[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_features': 4,\n",
       " 'h_features': [200, 200, 200],\n",
       " 'out_features': 4,\n",
       " 'activation': ReLU(),\n",
       " 'norm_nodes': 'gn',\n",
       " 'dropout': 0.0,\n",
       " 'train_lr': 0.1,\n",
       " 'train_optimizer_name': 'adamw',\n",
       " 'train_scheduler_mode': 'max_val_mcc',\n",
       " 'train_label_smoothing': 0.0,\n",
       " 'train_use_edge_weight': False,\n",
       " 'train_scheduler_patience': 20,\n",
       " 'train_self_loop': False,\n",
       " 'train_drop_edges': 0,\n",
       " 'train_loss': 0.68153757,\n",
       " 'train_acc': 0.7524752020835876,\n",
       " 'val_acc': 0.7209300398826599,\n",
       " 'epoch': 59,\n",
       " 'model_class': 'fnn',\n",
       " 'path_name': '0.72_4_[200_200_200]_4_ReLU()_gn_0.0_0.1_adamw_max_val_mcc_0.0_False_20_False_0',\n",
       " 'train_mcc': 0.6758830388377763,\n",
       " 'val_mcc': 0.6256091983969745,\n",
       " 'test_mcc': 0.43573826897645357,\n",
       " 'train_rmse': 0.6674912392349772,\n",
       " 'val_rmse': 0.7470873676376284,\n",
       " 'test_rmse': 1.0145101129268101,\n",
       " 'test_acc': 0.5699999928474426}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = res_edges[2]\n",
    "# ascending order\n",
    "sort_idx = np.argsort([k['dict'][metric_filter_1] for k in all])[::-1]\n",
    "all[sort_idx[0]]['dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_features': 4,\n",
       " 'h_features': [100, 100, 100],\n",
       " 'out_features': 4,\n",
       " 'activation': ReLU(),\n",
       " 'norm_nodes': 'gn',\n",
       " 'dropout': 0.0,\n",
       " 'train_lr': 0.1,\n",
       " 'train_optimizer_name': 'adamw',\n",
       " 'train_scheduler_mode': 'max_val_mcc',\n",
       " 'train_label_smoothing': 0.0,\n",
       " 'train_use_edge_weight': False,\n",
       " 'train_scheduler_patience': 20,\n",
       " 'train_self_loop': False,\n",
       " 'train_drop_edges': 0,\n",
       " 'train_loss': 0.65743846,\n",
       " 'train_acc': 0.7326732277870178,\n",
       " 'val_acc': 0.6511626243591309,\n",
       " 'epoch': 80,\n",
       " 'model_class': 'fnn',\n",
       " 'path_name': '0.65_4_[100_100_100]_4_ReLU()_gn_0.0_0.1_adamw_max_val_mcc_0.0_False_20_False_0_80',\n",
       " 'train_mcc': 0.6480466318452746,\n",
       " 'val_mcc': 0.5308141572475455,\n",
       " 'test_mcc': 0.44335953123553307,\n",
       " 'train_rmse': 0.7243980088649642,\n",
       " 'val_rmse': 0.8760375907831331,\n",
       " 'test_rmse': 0.9821483516329825,\n",
       " 'test_acc': 0.5730769038200378}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = res_edges[2]\n",
    "# ascending order\n",
    "sort_idx = np.argsort([k['dict'][metric_filter_2] for k in all])[::-1]\n",
    "all[sort_idx[0]]['dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty([all[k]['dict'] for k in sort_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logistic_regression': 0.3958333333333333, 'random_forest': 1.0, 'knn_classifier': 0.6736111111111112}\n",
      "{'random_forest': 0.5930769230769231}\n",
      "{'logistic_regression': 0.42923076923076925, 'random_forest': 0.5930769230769231, 'knn_classifier': 0.45}\n"
     ]
    }
   ],
   "source": [
    "print(dict_small_acc_train)\n",
    "print(dict_small_acc_val)\n",
    "print(dict_small_acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logistic_regression': 0.24040692589472054, 'random_forest': 1.0, 'knn_classifier': 0.574872465961017}\n",
      "{'random_forest': 0.46179019637476154}\n",
      "{'logistic_regression': 0.271607138268044, 'random_forest': 0.46179019637476154, 'knn_classifier': 0.2755059559376615}\n"
     ]
    }
   ],
   "source": [
    "print(dict_small_mcc_train)\n",
    "print(dict_small_mcc_val)\n",
    "print(dict_small_mcc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logistic_regression': 1.2162099599438687, 'random_forest': 0.0, 'knn_classifier': 1.0}\n",
      "{'random_forest': 0.978617549246031}\n",
      "{'logistic_regression': 1.2275679520593055, 'random_forest': 0.978617549246031, 'knn_classifier': 1.3032503744336843}\n"
     ]
    }
   ],
   "source": [
    "print(dict_small_rmse_train)\n",
    "print(dict_small_rmse_val)\n",
    "print(dict_small_rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = f'{save_path}_gcn'\n",
    "log_dir = f'{log_path}_gcn'\n",
    "\n",
    "add_self_loop = True\n",
    "\n",
    "dataset_val = ContagionDataset(\n",
    "    raw_dir=data_dir,\n",
    "    drop_edges=0,\n",
    "    sets_lengths=sets_lengths,\n",
    "    add_self_loop = add_self_loop,\n",
    "    target = target,\n",
    ")\n",
    "\n",
    "gcn_model = dict(\n",
    "    in_features=[len(dataset_val.node_attributes)],\n",
    "    h_features=[[15] * 3, [10, 15, 20], [5, 10, 15, 20],],\n",
    "    out_features=[dataset_val.num_classes],\n",
    "    activation=[torch.nn.ReLU()],\n",
    "    norm_edges=['both', 'none'],\n",
    "    norm_nodes=[None, 'bn', 'gn'],\n",
    "    dropout=[0.2, 0.0],\n",
    "    # other\n",
    "    lr=[1e-1],\n",
    "    label_smoothing=[0.0, 0.2],\n",
    "    use_edge_weight=[True,],\n",
    "    drop_edges=[0,0.2],\n",
    ")\n",
    "list_model = [dict(zip(gcn_model.keys(), k)) for k in itertools.product(*gcn_model.values())]\n",
    "\n",
    "# gcn_model = dict(\n",
    "#     in_features=[len(dataset_val.node_attributes)],\n",
    "#     h_features=[[5, 10], [10, 15], [5,5,5], [5, 10, 15], [5, 10, 15, 20], [5], [10], [15]],\n",
    "#     # h_features=[[5, 10], [10, 15], [5], [10], [15], [10,15]],\n",
    "#     out_features=[dataset_val.num_classes],\n",
    "#     activation=[torch.nn.ReLU()],\n",
    "#     norm_edges=['both', 'none'],\n",
    "#     norm_nodes=[None, 'bn', 'gn'],\n",
    "#     dropout=[0.2, 0.5, 0.0],\n",
    "#     # other\n",
    "#     lr=[1],\n",
    "#     label_smoothing=[0.0, 0.2, 0.4],\n",
    "#     use_edge_weight=[True, False],\n",
    "#     drop_edges=[0,0.2,0.4],\n",
    "# )\n",
    "# list_model = [{i:j[k] for i,j in gcn_model.items()} for k in range(len(gcn_model['in_features']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if do_train:\n",
    "    for d in tqdm(list_model):\n",
    "        d = d.copy()\n",
    "        lr = d.pop('lr')\n",
    "        ls = d.pop('label_smoothing')\n",
    "        drop_edges = d.pop('drop_edges')\n",
    "        use_edge_weight = d.pop('use_edge_weight')\n",
    "\n",
    "        # dataset_valid = ContagionDataset(\n",
    "        #     raw_dir=data_dir,\n",
    "        #     drop_edges=0,\n",
    "        #     sets_lengths=sets_lengths,\n",
    "        #     add_self_loop = add_self_loop,\n",
    "        #     target = target,\n",
    "        #     seed=seed,\n",
    "        # )\n",
    "\n",
    "        dataset_train = ContagionDataset(\n",
    "            raw_dir=data_dir,\n",
    "            drop_edges=drop_edges,\n",
    "            sets_lengths=sets_lengths,\n",
    "            add_self_loop = add_self_loop,\n",
    "            target = target,\n",
    "        )\n",
    "\n",
    "        train(\n",
    "            model=GCN(**d),\n",
    "            dict_model=d,\n",
    "            dataset_train=dataset_train,\n",
    "            dataset_val=dataset_val,\n",
    "            log_dir=log_dir,\n",
    "            save_path=save_model,\n",
    "            lr=lr,\n",
    "            optimizer_name=\"adamw\",\n",
    "            n_epochs=100,\n",
    "            scheduler_mode='max_val_mcc',\n",
    "            debug_mode=False,\n",
    "            steps_save=10,\n",
    "            use_cpu=False,\n",
    "            label_smoothing=ls,\n",
    "            use_edge_weight=use_edge_weight,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_edges_gcn = test(\n",
    "    dataset=dataset_val,\n",
    "    save_path=save_model,\n",
    "    n_runs=1,\n",
    "    debug_mode=False,\n",
    "    use_cpu=False,\n",
    "    save=True,\n",
    "    use_edge_weight=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_edges = res_edges_gcn\n",
    "res_edges[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = res_edges[2]\n",
    "# ascending order\n",
    "sort_idx = np.argsort([k['dict'][metric_filter_1] for k in all])[::-1]\n",
    "all[sort_idx[0]]['dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = res_edges[2]\n",
    "# ascending order\n",
    "sort_idx = np.argsort([k['dict'][metric_filter_2] for k in all])[::-1]\n",
    "all[sort_idx[0]]['dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty([all[k]['dict'] for k in sort_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = f'{save_path}_sage'\n",
    "log_dir = f'{log_path}_sage'\n",
    "\n",
    "dataset_val = ContagionDataset(\n",
    "    raw_dir=data_dir,\n",
    "    drop_edges=0,\n",
    "    sets_lengths=sets_lengths,\n",
    "    add_self_loop = True,\n",
    "    target = target,\n",
    ")\n",
    "\n",
    "# sage_model = dict(\n",
    "#     in_features = [len(dataset.node_attributes)],\n",
    "#     h_features = [[15] * 3, [20], [15], [20] * 2, [15] * 2, [25], [30]], \n",
    "#     out_features = [out_feats],\n",
    "#     # aggregator_type = ['mean', 'lstm'],\n",
    "#     aggregator_type = ['lstm'],\n",
    "#     norm_edges = ['right', 'none'],\n",
    "#     norm_nodes = [None, 'bn', 'gn'],\n",
    "#     activation = [torch.nn.ReLU()],\n",
    "#     feat_drop = [0.2, 0],\n",
    "#     # other\n",
    "#     lr=[1e-2],\n",
    "#     label_smoothing=[0.0, 0.2],\n",
    "#     use_edge_weight=[True],\n",
    "#     add_self_loop=[True],\n",
    "#     drop_edges=[0,0.2],\n",
    "# )\n",
    "# list_model = [dict(zip(sage_model.keys(), k)) for k in itertools.product(*sage_model.values())]\n",
    "\n",
    "sage_model = dict(\n",
    "    in_features = [len(dataset.node_attributes)],\n",
    "    h_features=[[200]*2],\n",
    "    out_features = [out_feats],\n",
    "    aggregator_type = ['lstm'],\n",
    "    norm_edges = ['none'],\n",
    "    norm_nodes = ['gn'],\n",
    "    activation = [torch.nn.ReLU()],\n",
    "    feat_drop = [0.0],\n",
    "    # other\n",
    "    lr=[1e-2],\n",
    "    label_smoothing=[0],\n",
    "    use_edge_weight=[True],\n",
    "    add_self_loop=[True],\n",
    "    drop_edges=[0],\n",
    ")\n",
    "list_model = [dict(zip(sage_model.keys(), k)) for k in itertools.product(*sage_model.values())]\n",
    "# list_model = [{i:j[k] for i,j in sage_model.items()} for k in range(len(sage_model['in_features']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if do_train:\n",
    "    for d in tqdm(list_model):\n",
    "        d = d.copy()\n",
    "        lr = d.pop('lr')\n",
    "        ls = d.pop('label_smoothing')\n",
    "        add_self_loop = d.pop('add_self_loop')\n",
    "        drop_edges = d.pop('drop_edges')\n",
    "        use_edge_weight = d.pop('use_edge_weight')\n",
    "\n",
    "        dataset_valid = ContagionDataset(\n",
    "            raw_dir=data_dir,\n",
    "            drop_edges=0,\n",
    "            sets_lengths=sets_lengths,\n",
    "            add_self_loop = add_self_loop,\n",
    "            target = target,\n",
    "        )\n",
    "\n",
    "        dataset_train = ContagionDataset(\n",
    "            raw_dir=data_dir,\n",
    "            drop_edges=drop_edges,\n",
    "            sets_lengths=sets_lengths,\n",
    "            add_self_loop = add_self_loop,\n",
    "            target = target,\n",
    "        )\n",
    "\n",
    "        train(\n",
    "            model=GraphSAGE(**d),\n",
    "            dict_model=d,\n",
    "            dataset_train=dataset_train,\n",
    "            dataset_val=dataset_valid,\n",
    "            log_dir=log_dir,\n",
    "            save_path=save_model,\n",
    "            lr=lr,\n",
    "            optimizer_name=\"adamw\",\n",
    "            n_epochs=1000,\n",
    "            scheduler_mode='max_val_mcc',\n",
    "            debug_mode=False,\n",
    "            steps_save=100,\n",
    "            use_cpu=False,\n",
    "            label_smoothing=ls,\n",
    "            use_edge_weight=use_edge_weight,\n",
    "            scheduler_patience=500,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:22<00:00,  4.37it/s]\n"
     ]
    }
   ],
   "source": [
    "res_edges_sage = test(\n",
    "    dataset=dataset_val,\n",
    "    save_path=save_model,\n",
    "    n_runs=1,\n",
    "    debug_mode=False,\n",
    "    use_cpu=False,\n",
    "    save=True,\n",
    "    use_edge_weight=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_features': 4,\n",
       " 'h_features': [200, 200],\n",
       " 'out_features': 4,\n",
       " 'aggregator_type': 'lstm',\n",
       " 'norm_edges': 'none',\n",
       " 'norm_nodes': 'gn',\n",
       " 'activation': ReLU(),\n",
       " 'feat_drop': 0.0,\n",
       " 'train_lr': 0.01,\n",
       " 'train_optimizer_name': 'adamw',\n",
       " 'train_scheduler_mode': 'max_val_mcc',\n",
       " 'train_label_smoothing': 0,\n",
       " 'train_use_edge_weight': True,\n",
       " 'train_scheduler_patience': 500,\n",
       " 'train_self_loop': True,\n",
       " 'train_drop_edges': 0,\n",
       " 'train_loss': 0.03350535,\n",
       " 'train_acc': 0.9900989532470703,\n",
       " 'val_acc': 0.7441858649253845,\n",
       " 'epoch': 800,\n",
       " 'model_class': 'sage',\n",
       " 'path_name': '0.74_4_[200_200]_4_lstm_none_gn_ReLU()_0.0_0.01_adamw_max_val_mcc_0_True_500_True_0_800',\n",
       " 'train_mcc': 0.9867449874811582,\n",
       " 'val_mcc': 0.6617904681234664,\n",
       " 'test_mcc': 0.5089238667396631,\n",
       " 'train_rmse': 0.09950371902099892,\n",
       " 'val_rmse': 0.8490761052804039,\n",
       " 'test_rmse': 1.1228398063700944,\n",
       " 'test_acc': 0.6299999952316284}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_edges = res_edges_sage\n",
    "res_edges[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_features': 4,\n",
       " 'h_features': [200, 200],\n",
       " 'out_features': 4,\n",
       " 'aggregator_type': 'lstm',\n",
       " 'norm_edges': 'none',\n",
       " 'norm_nodes': 'gn',\n",
       " 'activation': ReLU(),\n",
       " 'feat_drop': 0.0,\n",
       " 'train_lr': 0.01,\n",
       " 'train_optimizer_name': 'adamw',\n",
       " 'train_scheduler_mode': 'max_val_mcc',\n",
       " 'train_label_smoothing': 0,\n",
       " 'train_use_edge_weight': True,\n",
       " 'train_scheduler_patience': 500,\n",
       " 'train_self_loop': True,\n",
       " 'train_drop_edges': 0,\n",
       " 'train_loss': 0.033465955,\n",
       " 'train_acc': 0.9900989532470703,\n",
       " 'val_acc': 0.790697455406189,\n",
       " 'epoch': 799,\n",
       " 'model_class': 'sage',\n",
       " 'path_name': '0.79_4_[200_200]_4_lstm_none_gn_ReLU()_0.0_0.01_adamw_max_val_mcc_0_True_500_True_0',\n",
       " 'train_mcc': 0.9867449874811582,\n",
       " 'val_mcc': 0.7258189355987245,\n",
       " 'test_mcc': 0.5045434995420066,\n",
       " 'train_rmse': 0.09950371902099892,\n",
       " 'val_rmse': 0.777593185920953,\n",
       " 'test_rmse': 1.1276251422961716,\n",
       " 'test_acc': 0.6269230842590332}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = res_edges[2]\n",
    "# ascending order\n",
    "sort_idx = np.argsort([k['dict'][metric_filter_1] for k in all])[::-1]\n",
    "all[sort_idx[0]]['dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_features': 4,\n",
       " 'h_features': [200, 200],\n",
       " 'out_features': 4,\n",
       " 'aggregator_type': 'lstm',\n",
       " 'norm_edges': 'none',\n",
       " 'norm_nodes': 'gn',\n",
       " 'activation': ReLU(),\n",
       " 'feat_drop': 0.0,\n",
       " 'train_lr': 0.01,\n",
       " 'train_optimizer_name': 'adamw',\n",
       " 'train_scheduler_mode': 'max_val_mcc',\n",
       " 'train_label_smoothing': 0,\n",
       " 'train_use_edge_weight': True,\n",
       " 'train_scheduler_patience': 500,\n",
       " 'train_self_loop': True,\n",
       " 'train_drop_edges': 0,\n",
       " 'train_loss': 0.03350535,\n",
       " 'train_acc': 0.9900989532470703,\n",
       " 'val_acc': 0.7441858649253845,\n",
       " 'epoch': 800,\n",
       " 'model_class': 'sage',\n",
       " 'path_name': '0.74_4_[200_200]_4_lstm_none_gn_ReLU()_0.0_0.01_adamw_max_val_mcc_0_True_500_True_0_800',\n",
       " 'train_mcc': 0.9867449874811582,\n",
       " 'val_mcc': 0.6617904681234664,\n",
       " 'test_mcc': 0.5089238667396631,\n",
       " 'train_rmse': 0.09950371902099892,\n",
       " 'val_rmse': 0.8490761052804039,\n",
       " 'test_rmse': 1.1228398063700944,\n",
       " 'test_acc': 0.6299999952316284}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = res_edges[2]\n",
    "# ascending order\n",
    "sort_idx = np.argsort([k['dict'][metric_filter_2] for k in all])[::-1]\n",
    "all[sort_idx[0]]['dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty([all[k]['dict'] for k in sort_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = all[sort_idx[0]]['test_cm'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(325)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cm.labels==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from 'c:\\\\Users\\\\vibal\\\\PycharmProjects\\\\systemic-risk-predictor\\\\venv\\\\lib\\\\site-packages\\\\matplotlib\\\\pyplot.py'>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7169, 0.6603, 0.5382, 0.6066])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.class_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = f'{save_path}_gat'\n",
    "log_dir = f'{log_path}_gat'\n",
    "\n",
    "add_self_loop = True\n",
    "\n",
    "dataset_val = ContagionDataset(\n",
    "    raw_dir=data_dir,\n",
    "    drop_edges=0,\n",
    "    sets_lengths=sets_lengths,\n",
    "    add_self_loop = add_self_loop,\n",
    "    target = target,\n",
    ")\n",
    "\n",
    "gat_model = dict(\n",
    "    in_features = [len(dataset.node_attributes)],\n",
    "    h_features = [[10] * 2, [20], [20] * 2, [25], [25] * 2],\n",
    "    out_features = [out_feats],\n",
    "    num_heads = [[4] * 2, [2] * 2],\n",
    "    norm_nodes = [None, 'bn', 'gn'],\n",
    "    activation = [torch.nn.ReLU()],\n",
    "    negative_slope = [0.2, 0.4],\n",
    "    feat_drop = [0.2],\n",
    "    attn_drop = [0.2],\n",
    "    residual = [True],\n",
    "    # other\n",
    "    lr=[1e-2,],\n",
    "    label_smoothing=[0.0, 0.2],\n",
    "    use_edge_weight=[False],\n",
    "    drop_edges=[0,0.2],\n",
    ")\n",
    "list_model = [dict(zip(gat_model.keys(), k)) for k in itertools.product(*gat_model.values())]\n",
    "\n",
    "# gat_model = dict(\n",
    "#     in_features = [len(dataset.node_attributes)],\n",
    "#     # h_features = [[10], [15], [20]], \n",
    "#     h_features = [[10] * 3, [15] * 3, [20] * 3], \n",
    "#     out_features = [out_feats],\n",
    "#     # num_heads = [[4] * 4],\n",
    "#     num_heads = [[4, 2, 2]],\n",
    "#     norm_nodes = [None, 'bn', 'gn'],\n",
    "#     activation = [torch.nn.ReLU()],\n",
    "#     negative_slope = [0.2, 0.3, 0.4],\n",
    "#     feat_drop = [0.2],\n",
    "#     attn_drop = [0.2],\n",
    "#     residual = [True],\n",
    "#     # other\n",
    "#     lr=[1e-2,],\n",
    "#     label_smoothing=[0.0],\n",
    "#     use_edge_weight=[False],\n",
    "#     drop_edges=[0,],\n",
    "# )\n",
    "# list_model = [dict(zip(gat_model.keys(), k)) for k in itertools.product(*gat_model.values())]\n",
    "# list_model = [{i:j[k] for i,j in gat_model.items()} for k in range(len(gat_model['in_features']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if do_train:\n",
    "    for d in tqdm(list_model):\n",
    "        d = d.copy()\n",
    "        lr = d.pop('lr')\n",
    "        ls = d.pop('label_smoothing')\n",
    "        drop_edges = d.pop('drop_edges')\n",
    "        use_edge_weight = d.pop('use_edge_weight')\n",
    "\n",
    "        # dataset_valid = ContagionDataset(\n",
    "        #     raw_dir=data_dir,\n",
    "        #     drop_edges=0,\n",
    "        #     sets_lengths=sets_lengths,\n",
    "        #     add_self_loop = add_self_loop,\n",
    "        #     target = target,\n",
    "        #     seed=seed,\n",
    "        # )\n",
    "\n",
    "        dataset_train = ContagionDataset(\n",
    "            raw_dir=data_dir,\n",
    "            drop_edges=drop_edges,\n",
    "            sets_lengths=sets_lengths,\n",
    "            add_self_loop = add_self_loop,\n",
    "            target = target,\n",
    "        )\n",
    "\n",
    "        train(\n",
    "            model=GAT(**d),\n",
    "            dict_model=d,\n",
    "            dataset_train=dataset_train,\n",
    "            dataset_val=dataset_val,\n",
    "            log_dir=log_dir,\n",
    "            save_path=save_model,\n",
    "            lr=lr,\n",
    "            optimizer_name=\"adamw\",\n",
    "            n_epochs=100,\n",
    "            scheduler_mode='max_val_mcc',\n",
    "            debug_mode=False,\n",
    "            steps_save=10,\n",
    "            use_cpu=False,\n",
    "            label_smoothing=ls,\n",
    "            use_edge_weight=use_edge_weight,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "res_edges_gat = test(\n",
    "    dataset=dataset_val,\n",
    "    save_path=save_model,\n",
    "    n_runs=1,\n",
    "    debug_mode=False,\n",
    "    use_cpu=False,\n",
    "    save=True,\n",
    "    use_edge_weight=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_edges = res_edges_gat\n",
    "res_edges[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\vibal\\PycharmProjects\\systemic-risk-predictor\\notebooks\\europe_network\\models_clas_0.1\\models_training.ipynb Cell 68'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vibal/PycharmProjects/systemic-risk-predictor/notebooks/europe_network/models_clas_0.1/models_training.ipynb#ch0000067?line=1'>2</a>\u001b[0m \u001b[39m# ascending order\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vibal/PycharmProjects/systemic-risk-predictor/notebooks/europe_network/models_clas_0.1/models_training.ipynb#ch0000067?line=2'>3</a>\u001b[0m sort_idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margsort([k[\u001b[39m'\u001b[39m\u001b[39mdict\u001b[39m\u001b[39m'\u001b[39m][metric_filter_1] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mall\u001b[39m])[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/vibal/PycharmProjects/systemic-risk-predictor/notebooks/europe_network/models_clas_0.1/models_training.ipynb#ch0000067?line=3'>4</a>\u001b[0m \u001b[39mall\u001b[39m[sort_idx[\u001b[39m0\u001b[39;49m]][\u001b[39m'\u001b[39m\u001b[39mdict\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "all = res_edges[2]\n",
    "# ascending order\n",
    "sort_idx = np.argsort([k['dict'][metric_filter_1] for k in all])[::-1]\n",
    "all[sort_idx[0]]['dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = res_edges[2]\n",
    "# ascending order\n",
    "sort_idx = np.argsort([k['dict'][metric_filter_2] for k in all])[::-1]\n",
    "all[sort_idx[0]]['dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty([all[k]['dict'] for k in sort_idx])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37be9487e307834247f9cc00a1ec46ceeb3f522b7edf17e3b2d74c6ce713e314"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
