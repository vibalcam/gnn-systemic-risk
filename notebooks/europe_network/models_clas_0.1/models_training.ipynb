{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import itertools\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "from models.train import train, test\n",
    "from models.models import GCN, GAT, GraphSAGE, FNN\n",
    "from models.utils import ContagionDataset, set_seed\n",
    "from sklearn.metrics import matthews_corrcoef, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty(ld, indent=0):\n",
    "    return None\n",
    "    with open('result.txt', 'w', encoding='utf-8') as file:\n",
    "        for d in tqdm(ld):\n",
    "            file.write('{' + '\\n')\n",
    "            for key, value in d.items():\n",
    "                file.write('\\t' * (indent+1) + str(key) + ':' + str(value) + '\\n')\n",
    "                # file.write('\\t' * (indent+1) + str(key) + '\\n')\n",
    "                # file.write('\\t' * (indent+2) + str(value) + '\\n')\n",
    "            file.write('},\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_train = False\n",
    "\n",
    "seed = 4444\n",
    "set_seed(seed)\n",
    "\n",
    "metric_filter_1 = 'val_mcc'\n",
    "metric_filter_2 = 'test_mcc'\n",
    "\n",
    "data_dir = '../data'\n",
    "log_path = './logs'\n",
    "save_path = './saved'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big dataset: Additional stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets_lengths = (0.07, 0.03, 0.9)\n",
    "target = 'additional_stress'\n",
    "\n",
    "dataset = ContagionDataset(\n",
    "    raw_dir=data_dir,\n",
    "    drop_edges=0,\n",
    "    sets_lengths=sets_lengths,\n",
    "    target = target,\n",
    ")\n",
    "\n",
    "out_feats = dataset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(750)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(dataset[0].ndata['train_mask']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(375)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(dataset[0].ndata['val_mask']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(375)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(dataset[0].ndata['test_mask']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_small_acc_train = {}\n",
    "dict_small_acc_val = {}\n",
    "dict_small_acc_test = {}\n",
    "dict_small_rmse_train = {}\n",
    "dict_small_rmse_val = {}\n",
    "dict_small_rmse_test = {}\n",
    "dict_small_mcc_train = {}\n",
    "dict_small_mcc_val = {}\n",
    "dict_small_mcc_test = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train,x_test,y_train,y_test = train_test_split(dataset.node_features[0].to_numpy(), dataset.targets[0], test_size=0.25, random_state=seed)\n",
    "g_data = dataset.graphs[0].ndata\n",
    "feats = g_data['feat']\n",
    "labels = g_data['label']\n",
    "train_mask = g_data['train_mask']\n",
    "val_mask = g_data['val_mask']\n",
    "test_mask = g_data['test_mask']\n",
    "\n",
    "# train + val for training, test for test\n",
    "x_train,x_test = feats[torch.logical_not(test_mask)], feats[test_mask]\n",
    "y_train,y_test = labels[torch.logical_not(test_mask)], labels[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([144, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1300, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.75      0.53       325\n",
      "           1       0.45      0.03      0.06       315\n",
      "           2       0.38      0.69      0.49       327\n",
      "           3       0.93      0.24      0.38       333\n",
      "\n",
      "    accuracy                           0.43      1300\n",
      "   macro avg       0.54      0.43      0.36      1300\n",
      "weighted avg       0.55      0.43      0.37      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression(multi_class='multinomial',random_state=seed, max_iter=800).fit(x_train, y_train)\n",
    "print(classification_report(y_true=y_test, y_pred=model_lr.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.3958333333333333\n",
      "Test accuracy: 0.42923076923076925\n",
      "Train rmse: 1.2162099599438687\n",
      "Test rmse: 1.2275679520593055\n",
      "Train mcc: 0.24040692589472054\n",
      "Test mcc: 0.271607138268044\n"
     ]
    }
   ],
   "source": [
    "dict_small_acc_train['logistic_regression'] = model_lr.score(x_train, y_train)\n",
    "dict_small_acc_test['logistic_regression'] = model_lr.score(x_test, y_test)\n",
    "print(f\"Train accuracy: {dict_small_acc_train['logistic_regression']}\")\n",
    "print(f\"Test accuracy: {dict_small_acc_test['logistic_regression']}\")\n",
    "\n",
    "dict_small_rmse_train['logistic_regression'] = mean_squared_error(y_true=y_train,y_pred=model_lr.predict(x_train), squared=False)\n",
    "dict_small_rmse_test['logistic_regression'] = mean_squared_error(y_true=y_test,y_pred=model_lr.predict(x_test), squared=False)\n",
    "print(f\"Train rmse: {dict_small_rmse_train['logistic_regression']}\")\n",
    "print(f\"Test rmse: {dict_small_rmse_test['logistic_regression']}\")\n",
    "\n",
    "dict_small_mcc_train['logistic_regression'] = matthews_corrcoef(y_true=y_train,y_pred=model_lr.predict(x_train))\n",
    "dict_small_mcc_test['logistic_regression'] = matthews_corrcoef(y_true=y_test,y_pred=model_lr.predict(x_test))\n",
    "print(f\"Train mcc: {dict_small_mcc_train['logistic_regression']}\")\n",
    "print(f\"Test mcc: {dict_small_mcc_test['logistic_regression']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # x_train_rf,x_val_rf,y_train_rf,y_val_rf = train_test_split(x_train, y_train, test_size=0.2, random_state=seed)\n",
    "# x_train_rf,x_val_rf,x_test_rf = feats[train_mask], feats[val_mask], feats[test_mask]\n",
    "# y_train_rf,y_val_rf,y_test_rf = labels[train_mask], labels[val_mask], labels[test_mask]\n",
    "x_train_rf = x_train\n",
    "y_train_rf = y_train\n",
    "x_val_rf = x_test\n",
    "y_val_rf = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 13.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.44      0.48       325\n",
      "           1       0.42      0.54      0.47       315\n",
      "           2       0.62      0.49      0.55       327\n",
      "           3       0.77      0.85      0.81       333\n",
      "\n",
      "    accuracy                           0.58      1300\n",
      "   macro avg       0.59      0.58      0.58      1300\n",
      "weighted avg       0.59      0.58      0.58      1300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n = 20\n",
    "num_nodes = x_train_rf.shape[0]\n",
    "model_rf = None\n",
    "val_acc = 0.0\n",
    "for k in trange(1,num_nodes, (num_nodes - 1) // n):\n",
    "    tmp = RandomForestClassifier(random_state=seed, n_estimators=k).fit(x_train_rf,y_train_rf)\n",
    "    tmp_acc = tmp.score(x_val_rf, y_val_rf)\n",
    "    if val_acc < tmp_acc:\n",
    "        val_acc = tmp_acc\n",
    "        model_rf = tmp\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred=model_rf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=31, random_state=4444)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.0\n",
      "Val accuracy: 0.6976744186046512\n",
      "Test accuracy: 0.5823076923076923\n",
      "Train rmse: 0.0\n",
      "Val rmse: 0.8892118276421005\n",
      "Test rmse: 1.0003845414485526\n",
      "Train mcc: 1.0\n",
      "Val mcc: 0.5966396198534221\n",
      "Test mcc: 0.446182250538823\n"
     ]
    }
   ],
   "source": [
    "dict_small_acc_train['random_forest'] = model_rf.score(x_train_rf, y_train_rf)\n",
    "dict_small_acc_val['random_forest'] = model_rf.score(x_val_rf, y_val_rf)\n",
    "dict_small_acc_test['random_forest'] = model_rf.score(x_test, y_test)\n",
    "print(f\"Train accuracy: {dict_small_acc_train['random_forest']}\")\n",
    "print(f\"Val accuracy: {dict_small_acc_val['random_forest']}\")\n",
    "print(f\"Test accuracy: {dict_small_acc_test['random_forest']}\")\n",
    "\n",
    "dict_small_rmse_train['random_forest'] = mean_squared_error(y_true=y_train_rf,y_pred=model_rf.predict(x_train_rf), squared=False)\n",
    "dict_small_rmse_val['random_forest'] = mean_squared_error(y_true=y_val_rf,y_pred=model_rf.predict(x_val_rf), squared=False)\n",
    "dict_small_rmse_test['random_forest'] = mean_squared_error(y_true=y_test,y_pred=model_rf.predict(x_test), squared=False)\n",
    "print(f\"Train rmse: {dict_small_rmse_train['random_forest']}\")\n",
    "print(f\"Val rmse: {dict_small_rmse_val['random_forest']}\")\n",
    "print(f\"Test rmse: {dict_small_rmse_test['random_forest']}\")\n",
    "\n",
    "dict_small_mcc_train['random_forest'] = matthews_corrcoef(y_true=y_train_rf,y_pred=model_rf.predict(x_train_rf))\n",
    "dict_small_mcc_val['random_forest'] = matthews_corrcoef(y_true=y_val_rf,y_pred=model_rf.predict(x_val_rf))\n",
    "dict_small_mcc_test['random_forest'] = matthews_corrcoef(y_true=y_test,y_pred=model_rf.predict(x_test))\n",
    "print(f\"Train mcc: {dict_small_mcc_train['random_forest']}\")\n",
    "print(f\"Val mcc: {dict_small_mcc_val['random_forest']}\")\n",
    "print(f\"Test mcc: {dict_small_mcc_test['random_forest']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.61      0.47       325\n",
      "           1       0.35      0.39      0.37       315\n",
      "           2       0.50      0.20      0.28       327\n",
      "           3       0.64      0.60      0.62       333\n",
      "\n",
      "    accuracy                           0.45      1300\n",
      "   macro avg       0.47      0.45      0.44      1300\n",
      "weighted avg       0.47      0.45      0.44      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_knn = KNeighborsClassifier(n_neighbors=out_feats).fit(x_train,y_train)\n",
    "print(classification_report(y_true=y_test, y_pred=model_knn.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.6831683168316832\n",
      "Test accuracy: 0.45\n",
      "Train rmse: 0.9900495037128094\n",
      "Test rmse: 1.3032503744336843\n",
      "Train mcc: 0.5887687781396699\n",
      "Test mcc: 0.2755059559376615\n"
     ]
    }
   ],
   "source": [
    "dict_small_acc_train['knn_classifier'] = model_knn.score(x_train_rf, y_train_rf)\n",
    "dict_small_acc_test['knn_classifier'] = model_knn.score(x_test, y_test)\n",
    "print(f\"Train accuracy: {dict_small_acc_train['knn_classifier']}\")\n",
    "print(f\"Test accuracy: {dict_small_acc_test['knn_classifier']}\")\n",
    "\n",
    "dict_small_rmse_train['knn_classifier'] = mean_squared_error(y_true=y_train_rf,y_pred=model_knn.predict(x_train_rf), squared=False)\n",
    "dict_small_rmse_test['knn_classifier'] = mean_squared_error(y_true=y_test,y_pred=model_knn.predict(x_test), squared=False)\n",
    "print(f\"Train rmse: {dict_small_rmse_train['knn_classifier']}\")\n",
    "print(f\"Test rmse: {dict_small_rmse_test['knn_classifier']}\")\n",
    "\n",
    "dict_small_mcc_train['knn_classifier'] = matthews_corrcoef(y_true=y_train_rf,y_pred=model_knn.predict(x_train_rf))\n",
    "dict_small_mcc_test['knn_classifier'] = matthews_corrcoef(y_true=y_test,y_pred=model_knn.predict(x_test))\n",
    "print(f\"Train mcc: {dict_small_mcc_train['knn_classifier']}\")\n",
    "print(f\"Test mcc: {dict_small_mcc_test['knn_classifier']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = f'{save_path}_fnn'\n",
    "log_dir = f'{log_path}_fnn'\n",
    "\n",
    "dataset_val = ContagionDataset(\n",
    "    raw_dir=data_dir,\n",
    "    drop_edges=0,\n",
    "    sets_lengths=sets_lengths,\n",
    "    add_self_loop = False,\n",
    "    target = target,\n",
    ")\n",
    "\n",
    "fnn_model = dict(\n",
    "    in_features=[len(dataset_val.node_attributes)],\n",
    "    h_features=[[100], [100] * 2, [100] * 3, [200], [200]*2,[200]*3],\n",
    "    out_features=[dataset_val.num_classes],\n",
    "    activation=[torch.nn.ReLU()],\n",
    "    norm_nodes = [None, 'bn', 'gn'],\n",
    "    dropout=[0.2, 0.0],\n",
    "    # other\n",
    "    lr=[1e-1],\n",
    "    label_smoothing=[0.0, 0.2],\n",
    ")\n",
    "list_model = [dict(zip(fnn_model.keys(), k)) for k in itertools.product(*fnn_model.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [03:24<00:00,  2.85s/it]\n"
     ]
    }
   ],
   "source": [
    "if do_train:\n",
    "    for d in tqdm(list_model):\n",
    "        d = d.copy()\n",
    "        lr = d.pop('lr')\n",
    "        ls = d.pop('label_smoothing')\n",
    "\n",
    "        train(\n",
    "            model=FNN(**d),\n",
    "            dict_model=d,\n",
    "            dataset_train=dataset_val,\n",
    "            dataset_val=dataset_val,\n",
    "            log_dir=log_dir,\n",
    "            save_path=save_model,\n",
    "            lr=lr,\n",
    "            optimizer_name=\"adamw\",\n",
    "            n_epochs=100,\n",
    "            scheduler_mode='max_val_mcc',\n",
    "            debug_mode=False,\n",
    "            steps_save=10,\n",
    "            use_cpu=False,\n",
    "            label_smoothing=ls,\n",
    "            use_edge_weight=False,\n",
    "            scheduler_patience=20,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1299/1299 [00:58<00:00, 22.08it/s]\n"
     ]
    }
   ],
   "source": [
    "res_edges_fnn = test(\n",
    "    dataset=dataset_val,\n",
    "    save_path=save_model,\n",
    "    n_runs=1,\n",
    "    debug_mode=False,\n",
    "    use_cpu=False,\n",
    "    save=True,\n",
    "    use_edge_weight=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_features': 4,\n",
       " 'h_features': [200, 200, 200],\n",
       " 'out_features': 4,\n",
       " 'activation': ReLU(),\n",
       " 'norm_nodes': 'gn',\n",
       " 'dropout': 0.0,\n",
       " 'train_lr': 0.1,\n",
       " 'train_optimizer_name': 'adamw',\n",
       " 'train_scheduler_mode': 'max_val_mcc',\n",
       " 'train_label_smoothing': 0.0,\n",
       " 'train_use_edge_weight': False,\n",
       " 'train_scheduler_patience': 20,\n",
       " 'train_self_loop': False,\n",
       " 'train_drop_edges': 0,\n",
       " 'train_loss': 0.63593006,\n",
       " 'train_acc': 0.7623761892318726,\n",
       " 'val_acc': 0.6511626243591309,\n",
       " 'epoch': 80,\n",
       " 'model_class': 'fnn',\n",
       " 'path_name': '0.65_4_[200_200_200]_4_ReLU()_gn_0.0_0.1_adamw_max_val_mcc_0.0_False_20_False_0_80',\n",
       " 'train_mcc': 0.6864419429227578,\n",
       " 'val_mcc': 0.5332591106146854,\n",
       " 'test_mcc': 0.44188670454440704,\n",
       " 'train_rmse': 0.6821631290633241,\n",
       " 'val_rmse': 0.914991421995628,\n",
       " 'test_rmse': 0.9833224684319366,\n",
       " 'test_acc': 0.5746153593063354}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_edges = res_edges_fnn\n",
    "res_edges[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_features': 4,\n",
       " 'h_features': [100, 100, 100],\n",
       " 'out_features': 4,\n",
       " 'activation': ReLU(),\n",
       " 'norm_nodes': 'gn',\n",
       " 'dropout': 0.0,\n",
       " 'train_lr': 0.1,\n",
       " 'train_optimizer_name': 'adamw',\n",
       " 'train_scheduler_mode': 'max_val_mcc',\n",
       " 'train_label_smoothing': 0.0,\n",
       " 'train_use_edge_weight': False,\n",
       " 'train_scheduler_patience': 20,\n",
       " 'train_self_loop': False,\n",
       " 'train_drop_edges': 0,\n",
       " 'train_loss': 0.65743846,\n",
       " 'train_acc': 0.7326732277870178,\n",
       " 'val_acc': 0.6511626243591309,\n",
       " 'epoch': 80,\n",
       " 'model_class': 'fnn',\n",
       " 'path_name': '0.65_4_[100_100_100]_4_ReLU()_gn_0.0_0.1_adamw_max_val_mcc_0.0_False_20_False_0_80',\n",
       " 'train_mcc': 0.6480466318452746,\n",
       " 'val_mcc': 0.5308141572475455,\n",
       " 'test_mcc': 0.44335953123553307,\n",
       " 'train_rmse': 0.7243980088649642,\n",
       " 'val_rmse': 0.8760375907831331,\n",
       " 'test_rmse': 0.9821483516329825,\n",
       " 'test_acc': 0.5730769038200378}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = res_edges[2]\n",
    "# ascending order\n",
    "sort_idx = np.argsort([k['dict'][metric_filter_1] for k in all])[::-1]\n",
    "all[sort_idx[0]]['dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_features': 4,\n",
       " 'h_features': [200, 200, 200],\n",
       " 'out_features': 4,\n",
       " 'activation': ReLU(),\n",
       " 'norm_nodes': 'gn',\n",
       " 'dropout': 0.0,\n",
       " 'train_lr': 0.1,\n",
       " 'train_optimizer_name': 'adamw',\n",
       " 'train_scheduler_mode': 'max_val_mcc',\n",
       " 'train_label_smoothing': 0.0,\n",
       " 'train_use_edge_weight': False,\n",
       " 'train_scheduler_patience': 20,\n",
       " 'train_self_loop': False,\n",
       " 'train_drop_edges': 0,\n",
       " 'train_loss': 0.68153757,\n",
       " 'train_acc': 0.7524752020835876,\n",
       " 'val_acc': 0.7209300398826599,\n",
       " 'epoch': 59,\n",
       " 'model_class': 'fnn',\n",
       " 'path_name': '0.72_4_[200_200_200]_4_ReLU()_gn_0.0_0.1_adamw_max_val_mcc_0.0_False_20_False_0',\n",
       " 'train_mcc': 0.6758830388377763,\n",
       " 'val_mcc': 0.6256091983969745,\n",
       " 'test_mcc': 0.43573826897645357,\n",
       " 'train_rmse': 0.6674912392349772,\n",
       " 'val_rmse': 0.7470873676376284,\n",
       " 'test_rmse': 1.0145101129268101,\n",
       " 'test_acc': 0.5699999928474426}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = res_edges[2]\n",
    "# ascending order\n",
    "sort_idx = np.argsort([k['dict'][metric_filter_2] for k in all])[::-1]\n",
    "all[sort_idx[0]]['dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty([all[k]['dict'] for k in sort_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logistic_regression': 0.3958333333333333, 'random_forest': 1.0, 'knn_classifier': 0.6831683168316832}\n",
      "{'random_forest': 0.6976744186046512}\n",
      "{'logistic_regression': 0.42923076923076925, 'random_forest': 0.5823076923076923, 'knn_classifier': 0.45}\n"
     ]
    }
   ],
   "source": [
    "print(dict_small_acc_train)\n",
    "print(dict_small_acc_val)\n",
    "print(dict_small_acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logistic_regression': 0.24040692589472054, 'random_forest': 1.0, 'knn_classifier': 0.5887687781396699}\n",
      "{'random_forest': 0.5966396198534221}\n",
      "{'logistic_regression': 0.271607138268044, 'random_forest': 0.446182250538823, 'knn_classifier': 0.2755059559376615}\n"
     ]
    }
   ],
   "source": [
    "print(dict_small_mcc_train)\n",
    "print(dict_small_mcc_val)\n",
    "print(dict_small_mcc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logistic_regression': 1.2162099599438687, 'random_forest': 0.0, 'knn_classifier': 0.9900495037128094}\n",
      "{'random_forest': 0.8892118276421005}\n",
      "{'logistic_regression': 1.2275679520593055, 'random_forest': 1.0003845414485526, 'knn_classifier': 1.3032503744336843}\n"
     ]
    }
   ],
   "source": [
    "print(dict_small_rmse_train)\n",
    "print(dict_small_rmse_val)\n",
    "print(dict_small_rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = f'{save_path}_gcn'\n",
    "log_dir = f'{log_path}_gcn'\n",
    "\n",
    "add_self_loop = True\n",
    "\n",
    "dataset_val = ContagionDataset(\n",
    "    raw_dir=data_dir,\n",
    "    drop_edges=0,\n",
    "    sets_lengths=sets_lengths,\n",
    "    add_self_loop = add_self_loop,\n",
    "    target = target,\n",
    ")\n",
    "\n",
    "gcn_model = dict(\n",
    "    in_features=[len(dataset_val.node_attributes)],\n",
    "    h_features=[[15] * 3, [10, 15, 20], [5, 10, 15, 20],],\n",
    "    out_features=[dataset_val.num_classes],\n",
    "    activation=[torch.nn.ReLU()],\n",
    "    norm_edges=['both', 'none'],\n",
    "    norm_nodes=[None, 'bn', 'gn'],\n",
    "    dropout=[0.2, 0.0],\n",
    "    # other\n",
    "    lr=[1e-1],\n",
    "    label_smoothing=[0.0, 0.2],\n",
    "    use_edge_weight=[True,],\n",
    "    drop_edges=[0,0.2],\n",
    ")\n",
    "list_model = [dict(zip(gcn_model.keys(), k)) for k in itertools.product(*gcn_model.values())]\n",
    "\n",
    "# gcn_model = dict(\n",
    "#     in_features=[len(dataset_val.node_attributes)],\n",
    "#     h_features=[[5, 10], [10, 15], [5,5,5], [5, 10, 15], [5, 10, 15, 20], [5], [10], [15]],\n",
    "#     # h_features=[[5, 10], [10, 15], [5], [10], [15], [10,15]],\n",
    "#     out_features=[dataset_val.num_classes],\n",
    "#     activation=[torch.nn.ReLU()],\n",
    "#     norm_edges=['both', 'none'],\n",
    "#     norm_nodes=[None, 'bn', 'gn'],\n",
    "#     dropout=[0.2, 0.5, 0.0],\n",
    "#     # other\n",
    "#     lr=[1],\n",
    "#     label_smoothing=[0.0, 0.2, 0.4],\n",
    "#     use_edge_weight=[True, False],\n",
    "#     drop_edges=[0,0.2,0.4],\n",
    "# )\n",
    "# list_model = [{i:j[k] for i,j in gcn_model.items()} for k in range(len(gcn_model['in_features']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if do_train:\n",
    "    for d in tqdm(list_model):\n",
    "        d = d.copy()\n",
    "        lr = d.pop('lr')\n",
    "        ls = d.pop('label_smoothing')\n",
    "        drop_edges = d.pop('drop_edges')\n",
    "        use_edge_weight = d.pop('use_edge_weight')\n",
    "\n",
    "        # dataset_valid = ContagionDataset(\n",
    "        #     raw_dir=data_dir,\n",
    "        #     drop_edges=0,\n",
    "        #     sets_lengths=sets_lengths,\n",
    "        #     add_self_loop = add_self_loop,\n",
    "        #     target = target,\n",
    "        #     seed=seed,\n",
    "        # )\n",
    "\n",
    "        dataset_train = ContagionDataset(\n",
    "            raw_dir=data_dir,\n",
    "            drop_edges=drop_edges,\n",
    "            sets_lengths=sets_lengths,\n",
    "            add_self_loop = add_self_loop,\n",
    "            target = target,\n",
    "        )\n",
    "\n",
    "        train(\n",
    "            model=GCN(**d),\n",
    "            dict_model=d,\n",
    "            dataset_train=dataset_train,\n",
    "            dataset_val=dataset_val,\n",
    "            log_dir=log_dir,\n",
    "            save_path=save_model,\n",
    "            lr=lr,\n",
    "            optimizer_name=\"adamw\",\n",
    "            n_epochs=100,\n",
    "            scheduler_mode='max_val_mcc',\n",
    "            debug_mode=False,\n",
    "            steps_save=10,\n",
    "            use_cpu=False,\n",
    "            label_smoothing=ls,\n",
    "            use_edge_weight=use_edge_weight,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_edges_gcn = test(\n",
    "    dataset=dataset_val,\n",
    "    save_path=save_model,\n",
    "    n_runs=1,\n",
    "    debug_mode=False,\n",
    "    use_cpu=False,\n",
    "    save=True,\n",
    "    use_edge_weight=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_edges = res_edges_gcn\n",
    "res_edges[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = res_edges[2]\n",
    "# ascending order\n",
    "sort_idx = np.argsort([k['dict'][metric_filter_1] for k in all])[::-1]\n",
    "all[sort_idx[0]]['dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = res_edges[2]\n",
    "# ascending order\n",
    "sort_idx = np.argsort([k['dict'][metric_filter_2] for k in all])[::-1]\n",
    "all[sort_idx[0]]['dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty([all[k]['dict'] for k in sort_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = f'{save_path}_sage'\n",
    "log_dir = f'{log_path}_sage'\n",
    "\n",
    "dataset_val = ContagionDataset(\n",
    "    raw_dir=data_dir,\n",
    "    drop_edges=0,\n",
    "    sets_lengths=sets_lengths,\n",
    "    add_self_loop = True,\n",
    "    target = target,\n",
    ")\n",
    "\n",
    "# sage_model = dict(\n",
    "#     in_features = [len(dataset.node_attributes)],\n",
    "#     h_features = [[15] * 3, [20], [15], [20] * 2, [15] * 2, [25], [30]], \n",
    "#     out_features = [out_feats],\n",
    "#     # aggregator_type = ['mean', 'lstm'],\n",
    "#     aggregator_type = ['lstm'],\n",
    "#     norm_edges = ['right', 'none'],\n",
    "#     norm_nodes = [None, 'bn', 'gn'],\n",
    "#     activation = [torch.nn.ReLU()],\n",
    "#     feat_drop = [0.2, 0],\n",
    "#     # other\n",
    "#     lr=[1e-2],\n",
    "#     label_smoothing=[0.0, 0.2],\n",
    "#     use_edge_weight=[True],\n",
    "#     add_self_loop=[True],\n",
    "#     drop_edges=[0,0.2],\n",
    "# )\n",
    "# list_model = [dict(zip(sage_model.keys(), k)) for k in itertools.product(*sage_model.values())]\n",
    "\n",
    "sage_model = dict(\n",
    "    in_features = [len(dataset.node_attributes)],\n",
    "    h_features=[[200]*2],\n",
    "    out_features = [out_feats],\n",
    "    aggregator_type = ['lstm'],\n",
    "    norm_edges = ['none'],\n",
    "    norm_nodes = ['gn'],\n",
    "    activation = [torch.nn.ReLU()],\n",
    "    feat_drop = [0.0],\n",
    "    # other\n",
    "    lr=[1e-2],\n",
    "    label_smoothing=[0],\n",
    "    use_edge_weight=[True],\n",
    "    add_self_loop=[True],\n",
    "    drop_edges=[0],\n",
    ")\n",
    "list_model = [dict(zip(sage_model.keys(), k)) for k in itertools.product(*sage_model.values())]\n",
    "# list_model = [{i:j[k] for i,j in sage_model.items()} for k in range(len(sage_model['in_features']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [13:15<00:00, 795.47s/it]\n"
     ]
    }
   ],
   "source": [
    "if do_train:\n",
    "    for d in tqdm(list_model):\n",
    "        d = d.copy()\n",
    "        lr = d.pop('lr')\n",
    "        ls = d.pop('label_smoothing')\n",
    "        add_self_loop = d.pop('add_self_loop')\n",
    "        drop_edges = d.pop('drop_edges')\n",
    "        use_edge_weight = d.pop('use_edge_weight')\n",
    "\n",
    "        dataset_valid = ContagionDataset(\n",
    "            raw_dir=data_dir,\n",
    "            drop_edges=0,\n",
    "            sets_lengths=sets_lengths,\n",
    "            add_self_loop = add_self_loop,\n",
    "            target = target,\n",
    "        )\n",
    "\n",
    "        dataset_train = ContagionDataset(\n",
    "            raw_dir=data_dir,\n",
    "            drop_edges=drop_edges,\n",
    "            sets_lengths=sets_lengths,\n",
    "            add_self_loop = add_self_loop,\n",
    "            target = target,\n",
    "        )\n",
    "\n",
    "        train(\n",
    "            model=GraphSAGE(**d),\n",
    "            dict_model=d,\n",
    "            dataset_train=dataset_train,\n",
    "            dataset_val=dataset_valid,\n",
    "            log_dir=log_dir,\n",
    "            save_path=save_model,\n",
    "            lr=lr,\n",
    "            optimizer_name=\"adamw\",\n",
    "            n_epochs=1000,\n",
    "            scheduler_mode='max_val_mcc',\n",
    "            debug_mode=False,\n",
    "            steps_save=100,\n",
    "            use_cpu=False,\n",
    "            label_smoothing=ls,\n",
    "            use_edge_weight=use_edge_weight,\n",
    "            scheduler_patience=500,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:36<00:00,  2.69it/s]\n"
     ]
    }
   ],
   "source": [
    "res_edges_sage = test(\n",
    "    dataset=dataset_val,\n",
    "    save_path=save_model,\n",
    "    n_runs=1,\n",
    "    debug_mode=False,\n",
    "    use_cpu=False,\n",
    "    save=True,\n",
    "    use_edge_weight=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_features': 4,\n",
       " 'h_features': [200, 200],\n",
       " 'out_features': 4,\n",
       " 'aggregator_type': 'lstm',\n",
       " 'norm_edges': 'none',\n",
       " 'norm_nodes': 'gn',\n",
       " 'activation': ReLU(),\n",
       " 'feat_drop': 0.0,\n",
       " 'train_lr': 0.01,\n",
       " 'train_optimizer_name': 'adamw',\n",
       " 'train_scheduler_mode': 'max_val_mcc',\n",
       " 'train_label_smoothing': 0,\n",
       " 'train_use_edge_weight': True,\n",
       " 'train_scheduler_patience': 500,\n",
       " 'train_self_loop': True,\n",
       " 'train_drop_edges': 0,\n",
       " 'train_loss': 0.03350535,\n",
       " 'train_acc': 0.9900989532470703,\n",
       " 'val_acc': 0.7441858649253845,\n",
       " 'epoch': 800,\n",
       " 'model_class': 'sage',\n",
       " 'path_name': '0.74_4_[200_200]_4_lstm_none_gn_ReLU()_0.0_0.01_adamw_max_val_mcc_0_True_500_True_0_800',\n",
       " 'train_mcc': 0.9867449874811582,\n",
       " 'val_mcc': 0.6617904681234664,\n",
       " 'test_mcc': 0.5089238667396631,\n",
       " 'train_rmse': 0.09950371902099892,\n",
       " 'val_rmse': 0.8490761052804039,\n",
       " 'test_rmse': 1.1228398063700944,\n",
       " 'test_acc': 0.6299999952316284}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_edges = res_edges_sage\n",
    "res_edges[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_features': 4,\n",
       " 'h_features': [200, 200],\n",
       " 'out_features': 4,\n",
       " 'aggregator_type': 'lstm',\n",
       " 'norm_edges': 'none',\n",
       " 'norm_nodes': 'gn',\n",
       " 'activation': ReLU(),\n",
       " 'feat_drop': 0.0,\n",
       " 'train_lr': 0.01,\n",
       " 'train_optimizer_name': 'adamw',\n",
       " 'train_scheduler_mode': 'max_val_mcc',\n",
       " 'train_label_smoothing': 0,\n",
       " 'train_use_edge_weight': True,\n",
       " 'train_scheduler_patience': 500,\n",
       " 'train_self_loop': True,\n",
       " 'train_drop_edges': 0,\n",
       " 'train_loss': 0.03350535,\n",
       " 'train_acc': 0.9900989532470703,\n",
       " 'val_acc': 0.7441858649253845,\n",
       " 'epoch': 800,\n",
       " 'model_class': 'sage',\n",
       " 'path_name': '0.74_4_[200_200]_4_lstm_none_gn_ReLU()_0.0_0.01_adamw_max_val_mcc_0_True_500_True_0_800',\n",
       " 'train_mcc': 0.9867449874811582,\n",
       " 'val_mcc': 0.6617904681234664,\n",
       " 'test_mcc': 0.5089238667396631,\n",
       " 'train_rmse': 0.09950371902099892,\n",
       " 'val_rmse': 0.8490761052804039,\n",
       " 'test_rmse': 1.1228398063700944,\n",
       " 'test_acc': 0.6299999952316284}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = res_edges[2]\n",
    "# ascending order\n",
    "sort_idx = np.argsort([k['dict'][metric_filter_1] for k in all])[::-1]\n",
    "all[sort_idx[0]]['dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_features': 4,\n",
       " 'h_features': [200, 200],\n",
       " 'out_features': 4,\n",
       " 'aggregator_type': 'lstm',\n",
       " 'norm_edges': 'none',\n",
       " 'norm_nodes': 'gn',\n",
       " 'activation': ReLU(),\n",
       " 'feat_drop': 0.0,\n",
       " 'train_lr': 0.01,\n",
       " 'train_optimizer_name': 'adamw',\n",
       " 'train_scheduler_mode': 'max_val_mcc',\n",
       " 'train_label_smoothing': 0,\n",
       " 'train_use_edge_weight': True,\n",
       " 'train_scheduler_patience': 500,\n",
       " 'train_self_loop': True,\n",
       " 'train_drop_edges': 0,\n",
       " 'train_loss': 0.033465955,\n",
       " 'train_acc': 0.9900989532470703,\n",
       " 'val_acc': 0.790697455406189,\n",
       " 'epoch': 799,\n",
       " 'model_class': 'sage',\n",
       " 'path_name': '0.79_4_[200_200]_4_lstm_none_gn_ReLU()_0.0_0.01_adamw_max_val_mcc_0_True_500_True_0',\n",
       " 'train_mcc': 0.9867449874811582,\n",
       " 'val_mcc': 0.7258189355987245,\n",
       " 'test_mcc': 0.5045434995420066,\n",
       " 'train_rmse': 0.09950371902099892,\n",
       " 'val_rmse': 0.777593185920953,\n",
       " 'test_rmse': 1.1276251422961716,\n",
       " 'test_acc': 0.6269230842590332}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = res_edges[2]\n",
    "# ascending order\n",
    "sort_idx = np.argsort([k['dict'][metric_filter_2] for k in all])[::-1]\n",
    "all[sort_idx[0]]['dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty([all[k]['dict'] for k in sort_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = all[sort_idx[0]]['test_cm'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(325)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cm.labels==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from 'c:\\\\Users\\\\vibal\\\\PycharmProjects\\\\systemic-risk-predictor\\\\venv\\\\lib\\\\site-packages\\\\matplotlib\\\\pyplot.py'>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7077, 0.6603, 0.5352, 0.6066])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.class_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = f'{save_path}_gat'\n",
    "log_dir = f'{log_path}_gat'\n",
    "\n",
    "add_self_loop = True\n",
    "\n",
    "dataset_val = ContagionDataset(\n",
    "    raw_dir=data_dir,\n",
    "    drop_edges=0,\n",
    "    sets_lengths=sets_lengths,\n",
    "    add_self_loop = add_self_loop,\n",
    "    target = target,\n",
    ")\n",
    "\n",
    "gat_model = dict(\n",
    "    in_features = [len(dataset.node_attributes)],\n",
    "    h_features = [[10] * 2, [20], [20] * 2, [25], [25] * 2],\n",
    "    out_features = [out_feats],\n",
    "    num_heads = [[4] * 2, [2] * 2],\n",
    "    norm_nodes = [None, 'bn', 'gn'],\n",
    "    activation = [torch.nn.ReLU()],\n",
    "    negative_slope = [0.2, 0.4],\n",
    "    feat_drop = [0.2],\n",
    "    attn_drop = [0.2],\n",
    "    residual = [True],\n",
    "    # other\n",
    "    lr=[1e-2,],\n",
    "    label_smoothing=[0.0, 0.2],\n",
    "    use_edge_weight=[False],\n",
    "    drop_edges=[0,0.2],\n",
    ")\n",
    "list_model = [dict(zip(gat_model.keys(), k)) for k in itertools.product(*gat_model.values())]\n",
    "\n",
    "# gat_model = dict(\n",
    "#     in_features = [len(dataset.node_attributes)],\n",
    "#     # h_features = [[10], [15], [20]], \n",
    "#     h_features = [[10] * 3, [15] * 3, [20] * 3], \n",
    "#     out_features = [out_feats],\n",
    "#     # num_heads = [[4] * 4],\n",
    "#     num_heads = [[4, 2, 2]],\n",
    "#     norm_nodes = [None, 'bn', 'gn'],\n",
    "#     activation = [torch.nn.ReLU()],\n",
    "#     negative_slope = [0.2, 0.3, 0.4],\n",
    "#     feat_drop = [0.2],\n",
    "#     attn_drop = [0.2],\n",
    "#     residual = [True],\n",
    "#     # other\n",
    "#     lr=[1e-2,],\n",
    "#     label_smoothing=[0.0],\n",
    "#     use_edge_weight=[False],\n",
    "#     drop_edges=[0,],\n",
    "# )\n",
    "# list_model = [dict(zip(gat_model.keys(), k)) for k in itertools.product(*gat_model.values())]\n",
    "# list_model = [{i:j[k] for i,j in gat_model.items()} for k in range(len(gat_model['in_features']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [29:37<00:00,  7.41s/it]\n"
     ]
    }
   ],
   "source": [
    "if do_train:\n",
    "    for d in tqdm(list_model):\n",
    "        d = d.copy()\n",
    "        lr = d.pop('lr')\n",
    "        ls = d.pop('label_smoothing')\n",
    "        drop_edges = d.pop('drop_edges')\n",
    "        use_edge_weight = d.pop('use_edge_weight')\n",
    "\n",
    "        # dataset_valid = ContagionDataset(\n",
    "        #     raw_dir=data_dir,\n",
    "        #     drop_edges=0,\n",
    "        #     sets_lengths=sets_lengths,\n",
    "        #     add_self_loop = add_self_loop,\n",
    "        #     target = target,\n",
    "        #     seed=seed,\n",
    "        # )\n",
    "\n",
    "        dataset_train = ContagionDataset(\n",
    "            raw_dir=data_dir,\n",
    "            drop_edges=drop_edges,\n",
    "            sets_lengths=sets_lengths,\n",
    "            add_self_loop = add_self_loop,\n",
    "            target = target,\n",
    "        )\n",
    "\n",
    "        train(\n",
    "            model=GAT(**d),\n",
    "            dict_model=d,\n",
    "            dataset_train=dataset_train,\n",
    "            dataset_val=dataset_val,\n",
    "            log_dir=log_dir,\n",
    "            save_path=save_model,\n",
    "            lr=lr,\n",
    "            optimizer_name=\"adamw\",\n",
    "            n_epochs=100,\n",
    "            scheduler_mode='max_val_mcc',\n",
    "            debug_mode=False,\n",
    "            steps_save=10,\n",
    "            use_cpu=False,\n",
    "            label_smoothing=ls,\n",
    "            use_edge_weight=use_edge_weight,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3876/3876 [03:22<00:00, 19.15it/s]\n"
     ]
    }
   ],
   "source": [
    "res_edges_gat = test(\n",
    "    dataset=dataset_val,\n",
    "    save_path=save_model,\n",
    "    n_runs=1,\n",
    "    debug_mode=False,\n",
    "    use_cpu=False,\n",
    "    save=True,\n",
    "    use_edge_weight=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_features': 4,\n",
       " 'h_features': [20],\n",
       " 'out_features': 4,\n",
       " 'num_heads': [4, 4],\n",
       " 'norm_nodes': None,\n",
       " 'activation': ReLU(),\n",
       " 'negative_slope': 0.2,\n",
       " 'feat_drop': 0.2,\n",
       " 'attn_drop': 0.2,\n",
       " 'residual': True,\n",
       " 'train_lr': 0.01,\n",
       " 'train_optimizer_name': 'adamw',\n",
       " 'train_scheduler_mode': 'max_val_mcc',\n",
       " 'train_label_smoothing': 0.2,\n",
       " 'train_use_edge_weight': False,\n",
       " 'train_scheduler_patience': 10,\n",
       " 'train_self_loop': True,\n",
       " 'train_drop_edges': 0.2,\n",
       " 'train_loss': 23888220.0,\n",
       " 'train_acc': 0.39603957533836365,\n",
       " 'val_acc': 0.4186045527458191,\n",
       " 'epoch': 20,\n",
       " 'model_class': 'gat',\n",
       " 'path_name': '0.42_4_[20]_4_[4_4]_None_ReLU()_0.2_0.2_0.2_True_0.01_adamw_max_val_mcc_0.2_False_10_True_0.2_20',\n",
       " 'train_mcc': 0.20711174744274033,\n",
       " 'val_mcc': 0.2351238761039608,\n",
       " 'test_mcc': 0.26539399095925403,\n",
       " 'train_rmse': 1.7148160424389376,\n",
       " 'val_rmse': 1.5249857033260468,\n",
       " 'test_rmse': 1.5984235123480435,\n",
       " 'test_acc': 0.4327440559864044}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_edges = res_edges_gat\n",
    "res_edges[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_features': 4,\n",
       " 'h_features': [20],\n",
       " 'out_features': 4,\n",
       " 'num_heads': [4, 4],\n",
       " 'norm_nodes': None,\n",
       " 'activation': ReLU(),\n",
       " 'negative_slope': 0.2,\n",
       " 'feat_drop': 0.2,\n",
       " 'attn_drop': 0.2,\n",
       " 'residual': True,\n",
       " 'train_lr': 0.01,\n",
       " 'train_optimizer_name': 'adamw',\n",
       " 'train_scheduler_mode': 'max_val_mcc',\n",
       " 'train_label_smoothing': 0.2,\n",
       " 'train_use_edge_weight': False,\n",
       " 'train_scheduler_patience': 10,\n",
       " 'train_self_loop': True,\n",
       " 'train_drop_edges': 0.2,\n",
       " 'train_loss': 23888220.0,\n",
       " 'train_acc': 0.39603957533836365,\n",
       " 'val_acc': 0.4186045527458191,\n",
       " 'epoch': 20,\n",
       " 'model_class': 'gat',\n",
       " 'path_name': '0.42_4_[20]_4_[4_4]_None_ReLU()_0.2_0.2_0.2_True_0.01_adamw_max_val_mcc_0.2_False_10_True_0.2_20',\n",
       " 'train_mcc': 0.20711174744274033,\n",
       " 'val_mcc': 0.2351238761039608,\n",
       " 'test_mcc': 0.26539399095925403,\n",
       " 'train_rmse': 1.7148160424389376,\n",
       " 'val_rmse': 1.5249857033260468,\n",
       " 'test_rmse': 1.5984235123480435,\n",
       " 'test_acc': 0.4327440559864044}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = res_edges[2]\n",
    "# ascending order\n",
    "sort_idx = np.argsort([k['dict'][metric_filter_1] for k in all])[::-1]\n",
    "all[sort_idx[0]]['dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_features': 4,\n",
       " 'h_features': [10, 10],\n",
       " 'out_features': 4,\n",
       " 'num_heads': [4, 4],\n",
       " 'norm_nodes': 'bn',\n",
       " 'activation': ReLU(),\n",
       " 'negative_slope': 0.4,\n",
       " 'feat_drop': 0.2,\n",
       " 'attn_drop': 0.2,\n",
       " 'residual': True,\n",
       " 'train_lr': 0.01,\n",
       " 'train_optimizer_name': 'adamw',\n",
       " 'train_scheduler_mode': 'max_val_mcc',\n",
       " 'train_label_smoothing': 0.0,\n",
       " 'train_use_edge_weight': False,\n",
       " 'train_scheduler_patience': 10,\n",
       " 'train_self_loop': True,\n",
       " 'train_drop_edges': 0.2,\n",
       " 'train_loss': 1.3743111,\n",
       " 'train_acc': 0.46534648537635803,\n",
       " 'val_acc': 0.5116277933120728,\n",
       " 'epoch': 34,\n",
       " 'model_class': 'gat',\n",
       " 'path_name': '0.51_4_[10_10]_4_[4_4]_bn_ReLU()_0.4_0.2_0.2_True_0.01_adamw_max_val_mcc_0.0_False_10_True_0.2',\n",
       " 'train_mcc': 0.32665719463540405,\n",
       " 'val_mcc': 0.38619071793905996,\n",
       " 'test_mcc': 0.18428499170486207,\n",
       " 'train_rmse': 1.42467644407319,\n",
       " 'val_rmse': 1.293993278441261,\n",
       " 'test_rmse': 1.5336351895729268,\n",
       " 'test_acc': 0.3712528944015503}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = res_edges[2]\n",
    "# ascending order\n",
    "sort_idx = np.argsort([k['dict'][metric_filter_2] for k in all])[::-1]\n",
    "all[sort_idx[0]]['dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty([all[k]['dict'] for k in sort_idx])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37be9487e307834247f9cc00a1ec46ceeb3f522b7edf17e3b2d74c6ce713e314"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
